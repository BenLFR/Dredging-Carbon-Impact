# ==============================================================================
# 1. Chargement des bibliothÃ¨ques nÃ©cessaires (VERSION SANS SF)
# ==============================================================================
library(data.table)    # Manipulation efficace des donnÃ©es
library(lubridate)     # Gestion des dates
library(mclust)        # ModÃ¨le de mÃ©lange pour la vitesse
# library(ranger)      # â¬…ï¸  plus utilisÃ© (GLM Ã  la place)
library(caret)         # Partitionnement et Ã©valuation
library(pROC)          # AUC & courbes ROC
library(ggplot2)       # Visualisations
# library(marmap)      # (optionnel) bathymÃ©trie - DÃ‰SACTIVÃ‰
# library(raster)      # (optionnel) raster - DÃ‰SACTIVÃ‰
# library(sf)          # DonnÃ©es spatiales - DÃ‰SACTIVÃ‰ (problÃ¨me installation)
library(dbscan)        # HDBSCAN
library(dplyr)         # Pipes
library(zoo)           # Moyenne glissante
if (!require(depmixS4)) install.packages("depmixS4")
library(depmixS4)      # HMM
if (!require(pbapply)) install.packages("pbapply")
library(pbapply)       # barre de progression (pour d'autres usages)
if (!require(matrixStats)) { install.packages("matrixStats"); library(matrixStats) }
if (!require(geosphere))   { install.packages("geosphere");   library(geosphere)   }

# ==============================================================================
# 1.a Fonctions de dÃ©bogage
# ==============================================================================
dbg_head <- function(msg) {
  cat(sprintf("[%s] %s\n", Sys.time(), msg))
  flush.console()
}

dbg_mem_mb <- function() {
  round(sum(gc()[,2]) * 8 / 1024, 1)  # Approximation en Mo
}

dbg_time <- function() {
  format(Sys.time(), "%H:%M:%S")
}

# ======================================================================
# 1.b  CONFIG PARALLÃ‰LISME  â”€ utilise exactement les cÅ“urs Slurm
# ======================================================================
n_threads <- as.integer(Sys.getenv("SLURM_CPUS_PER_TASK", "1"))

## Bas-niveau (OpenMP / BLAS)
Sys.setenv(OMP_NUM_THREADS      = n_threads,
           OPENBLAS_NUM_THREADS = n_threads)

## data.table
data.table::setDTthreads(n_threads)

## mclapply / pbapply
options(mc.cores = n_threads)
Sys.setenv(MC_CORES = n_threads)

## ranger â€“ on garde la valeur dans une variable
ranger_threads <- n_threads

dbg_head(sprintf("CONFIG : %d threads allouÃ©s", n_threads))

# ------------------------------------------------------------------
# TABLE DE MAPPING : ssvid (MMSI)  â†’  IMO  â†’  Nom canonique "Navire"
# ------------------------------------------------------------------
mmsi_map <- data.table(
  ssvid = c(209469000, 210138000, 245508000, 246351000,
            253193000, 253373000, 253403000, 253422000,
            253688000, 312062000, 533180137),
  
  IMO_number = c(9132454, 9164031, 9229556, 9454096,
                 9187473, 9429572, 9429584, 9528079,
                 9574523, 8119728, 9568782),
  
  Navire = c("Fairway",
             "Queen Of The Netherlands",
             "Ham 318 Sleephopperzuiger",
             "Vox Maxima",
             "Vasco Da Gama",
             "Cristobal Colon",
             "Leiv Eiriksson",
             "Charles Darwin",
             "Congo River",
             "Goryo 6 Ho",
             "Inai Kenanga")
)
setkey(mmsi_map, ssvid)   # index pour merge rapide

# ------------------------------------------------------------------
# 2.c  Lecture des anciens CSV et retrait des navires mis Ã  jour
# ------------------------------------------------------------------
ais_directory <- "~/scratch/AIS_data"
out_dir       <- "~/scratch/output"
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)

ais_old <- load_AIS_files(ais_directory)

## 2.c-1  Sâ€™assurer que la colonne Navire existe ----------------------
if (!"Navire" %in% names(ais_old)) {
  # a) si un ssvid est prÃ©sent on reconstruit le nom via mmsi_map
  if ("ssvid" %in% names(ais_old)) {
    ais_old <- merge(
      ais_old, 
      mmsi_map[, .(ssvid, Navire)], 
      by = "ssvid", 
      all.x = TRUE
    )
  }
  # b) sinon on fabrique un nom gÃ©nÃ©rique Ã  partir du fichier
  if (!"Navire" %in% names(ais_old)) {
    ais_old[, Navire := paste0("unknown_", .I)]
  }
}

## 2.c-2  Normaliser la casse (navire â†’ Navire)
if ("navire" %in% names(ais_old) && !"Navire" %in% names(ais_old)) {
  setnames(ais_old, "navire", "Navire")
}

## 2.c-3  Supprimer les traces des navires remplacÃ©s
vessels_updated <- unique(df_new$Navire)
ais_old <- ais_old[!Navire %chin% vessels_updated]

## 2.d  Fusion ancien + nouveau (et FINI : on ne relira plus les anciens)
ais_data <- rbindlist(list(ais_old, df_new), use.names = TRUE, fill = TRUE)

dbg_head(sprintf("Jeu fusionnÃ© : %d pings, %d navires",
                 nrow(ais_data), length(unique(ais_data$Navire))))

# ------------------------------------------------------------------
# 3. Conversion du Timestamp  (plus de double-chargement)
# ------------------------------------------------------------------
ais_data[, Timestamp := as.POSIXct(
  Timestamp, format = "%Y-%m-%d %H:%M:%S", tz = "UTC")]

ais_data[, Annee := year(Timestamp)]

# ==============================================================================
# 3.1 FenÃªtre temporelle Â« core Â»
# ==============================================================================
core_years <- 2012:2024
ais_data_core <- ais_data[Annee %in% core_years]

# ==============================================================================
# 4. CaractÃ©ristiques navires
# ==============================================================================
vessel_specs <- data.table(
  Navire = c("Cristobal Colon","Leiv Eiriksson","Ham 318 Sleephopperzuiger",
             "Fairway","Queen Of The Netherlands","Inai Kenanga",
             "Vasco Da Gama","Vox Maxima","Charles Darwin",
             "Congo River","Goryo 6 Ho"),
  Owner = c("Dredging & Maritime Management","Jan De Nul Luxembourg","Ham 318",
            "Boskalis Westminster Shipping","Boskalis Westminster Shipping","Inai Kiara",
            "Flanders Dredging Corp","Vox Maxima","Jan De Nul Luxembourg",
            "CRiver Shipping","Hyundai Engineering & Steel"),
  total_installed_power_kW = c(38364,38364,28636,27550,27634,33335,37060,31309,23600,25445,12799),
  hopper_capacity_m3       = c(46000,45458,37293,35508,35500,NA,33125,31200,30500,30000,27000),
  length_overall_m         = c(223,223,227.2,230.71,230.71,197.7,201,195,183.2,168,224),
  draught_m                = c(15.15,15.15,13.37,11.03,11.03,NA,14.6,12.25,13,9.86,12.33),
  sailing_speed_knots      = c(18,18,17.3,16.1,16.1,NA,16.5,17,14,16.6,12),
  suction_pipe_diameter_mm = c(2600,1300,1200,1200,1200,2400,1400,1300,1200,1300,60),
  dredging_depth_m         = c(155,155,70,55,83,NA,60,70,93.5,36,NA),
  IMO_number               = c(9429572,9429584,9229556,9132454,9164031,9568782,
                               9187473,9454096,9528079,9574523,8119728)
)
ais_data_core <- merge(ais_data_core, vessel_specs, by = "Navire", all.x = TRUE)

# ==============================================================================
# 5. Classification vitesse grossiÃ¨re
# ==============================================================================
ais_data_core[, Activity := fifelse(Speed < 0.5, "manoeuvres/arrets",
                             fifelse(Speed < 3,  "dragage_potentiel",
                             fifelse(Speed < 10, "transit_loaded",
                             fifelse(Speed < 18, "transit_unloaded","Autre"))))]

# ==============================================================================
# 6. Feature engineering    â‡  REMPLACER TOUT CE BLOC
# ==============================================================================
# â†’ AccÃ©lÃ©ration calculÃ©e par segment, pas sur tout le jeu
ais_data_core[, Accel := {
  dV <- c(NA, diff(Speed))
  dt <- c(NA, diff(as.numeric(Timestamp)))
  dV / dt
}, by = Seg_id]
ais_data_core[is.na(Accel) | !is.finite(Accel), Accel := 0]

# â†’ Variation de cap corrigÃ©e (359Â° â†’ 1Â° = 2Â°)
ais_data_core[, Course_change := {
  delta <- c(NA, abs(diff(Course)))
  delta <- pmin(delta, 360 - delta)          # wrap-around
  delta
}, by = Seg_id]
ais_data_core[is.na(Course_change), Course_change := 0]

# Normalisation (95áµ‰ percentile recalculÃ© aprÃ¨s correction)
q95 <- quantile(ais_data_core$Course_change, 0.95, na.rm = TRUE)
ais_data_core[, norm_course_change := pmax(0, pmin(1, 1 - Course_change/q95))]

## 6.b  Flag arrÃªt / mouvement (Ã  mettre juste aprÃ¨s avoir crÃ©Ã© ais_data_core)

ais_data_core[, is_stop := Speed <= 0.3]   # 0.3 kn = seuil arrÃªt


# ==============================================================================
# 7.  ModÃ©lisation Ã  5 composantes : 1 Â« stop Â» + 4 GMM sur les points en mouvement
# ==============================================================================

## 7.a  PrÃ©-traitement ----------------------------------------------------------
# - on limite les vitesses Ã  0â€“20 kn
# - on crÃ©e un flag clair pour les arrÃªts (â‰¤ 0,3 kn)
ais_data_core[, is_stop := Speed <= 0.3]
ais_data_core <- ais_data_core[Speed <= 20]               # on Ã©carte les outliers > 20 kn

## 7.b  Ajustement dâ€™un GMM Ã  4 composantes sur les points en mouvement ---------
library(mclust)

speeds_move <- ais_data_core[is_stop == FALSE, Speed]     # n_move observations
gmm4        <- Mclust(speeds_move, G = 4, verbose = FALSE)  # 4 composantes gaussiennes

## 7.c  ProbabilitÃ©s a posteriori ----------------------------------------------
# a) prÃ©dictions GMM pour les vitesses en mouvement
z_move <- predict(gmm4, newdata = speeds_move)$z          # n_move Ã— 4

# b) initialisation des colonnes p_component_1 â€¦ p_component_5 Ã  0
ais_data_core[, paste0("p_component_", 1:5) := 0.0]

# c) attribution : composante 1 â‰” arrÃªts, composantes 2â€“5 â‰” sorties GMM
ais_data_core[is_stop == TRUE,  p_component_1 := 1]
ais_data_core[is_stop == FALSE, paste0("p_component_", 2:5) := as.data.table(z_move)]

# d) composante la plus probable (1â€“5)
ais_data_core[, comp := apply(.SD, 1, which.max),
              .SDcols = paste0("p_component_", 1:5)]

## 7.d  RÃ©sumÃ© des composantes --------------------------------------------------
gmm_summary <- data.table(
  component  = 1:5,
  mean_knots = c(0, round(gmm4$parameters$mean, 2)),       # 0 kn pour les stops
  sd_knots   = c(0, round(
    if (!is.null(gmm4$parameters$variance$sigmasq)) {
      sqrt(gmm4$parameters$variance$sigmasq)
    } else {
      rep(sqrt(gmm4$parameters$variance$sigma2), 4)
    }, 2))
)

print(gmm_summary)

## 7.e  Diagnostics rapides -----------------------------------------------------
summary(ais_data_core$Speed)                # min, max, quantiles
hist(ais_data_core$Speed, breaks = 200,
     main = "Distribution des vitesses filtrÃ©es (â‰¤ 20 kn)",
     xlab  = "Speed [knots]")


# ==============================================================================
# 8. Lissage comportemental
# ==============================================================================

## 8-a. Ã©tiquettes initiales ----------------------------------------------------
ais_data_core[, behavior := 
                fifelse(comp == 1, "stops",
                        fifelse(comp == 2, "slow_maneuvers",
                                fifelse(comp == 3, "dredging",
                                        fifelse(comp == 4, "loaded_transit",
                                                fifelse(comp == 5, "unloaded_transit", NA_character_)
                                        )
                                )
                        )
                )
]

# Convertir Lon et Lat en numÃ©rique
ais_data_core[, `:=`(
  Lon = as.numeric(Lon),
  Lat = as.numeric(Lat)
)]

## 8-b. matrice des coÃ»ts --------------------------------------------------------
transition_cost <- matrix(c(
  0, 2, 2, 2, 2,
  1, 0, 2, 3, 2,
  2, 2, 0, 2, 2,
  3, 3, 2, 0, 2,
  2, 2, 2, 2, 0
), 5, 5, byrow = TRUE,
dimnames = list(
  c("stops","slow_maneuvers","dredging",
    "loaded_transit","unloaded_transit"),
  c("stops","slow_maneuvers","dredging",
    "loaded_transit","unloaded_transit")))

## 8-c. lissage amÃ©liorÃ© ---------------------------------------------------------
smooth_behavior_transition <- function(labels, speeds,
                                       transition_cost,
                                       threshold   = 3,
                                       dredge_min  = 1,   # kn
                                       dredge_max  = 3.5) {
  
  ## (1) run-length smoothing -----------------------------------------------
  r   <- rle(labels)
  cum <- cumsum(r$lengths)
  beg <- c(1, head(cum, -1) + 1)
  
  for (i in seq_along(r$lengths)) {
    if (r$lengths[i] < threshold) {
      vbar <- mean(speeds[beg[i]:cum[i]])
      if (vbar <= dredge_max) {
        prev_lab <- if (i > 1)               r$values[i-1] else NA
        next_lab <- if (i < length(r$values)) r$values[i+1] else NA
        c_prev   <- if (!is.na(prev_lab)) transition_cost[prev_lab , r$values[i]] else Inf
        c_next   <- if (!is.na(next_lab)) transition_cost[next_lab , r$values[i]] else Inf
        r$values[i] <- if (c_prev < c_next) prev_lab else next_lab
      }
    }
  }
  lbl <- inverse.rle(r)
  
  ## (2) cohÃ©rence vitesse / label -------------------------------------------
  bad <- which(lbl == "dredging" &
                 (speeds < dredge_min | speeds > dredge_max))
  
  if (length(bad) > 0) {
    for (j in bad) {
      prev_lab <- if (j > 1)           lbl[j-1] else NA
      next_lab <- if (j < length(lbl)) lbl[j+1] else NA
      
      cand <- if (speeds[j] < dredge_min) {
        c("slow_maneuvers","stops")
      } else {
        c("loaded_transit","unloaded_transit")
      }
      
      best_lbl  <- cand[1]; best_cost <- Inf
      for (c in cand) {
        cp <- if (!is.na(prev_lab)) transition_cost[prev_lab , c] else 0
        cn <- if (!is.na(next_lab)) transition_cost[c       , next_lab] else 0
        if (cp + cn < best_cost) {
          best_lbl  <- c
          best_cost <- cp + cn
        }
      }
      lbl[j] <- best_lbl
    }
  }
  lbl
}

## 8-d. application du lissage --------------------------------------------------
ais_data_core[, behavior_smooth :=
                smooth_behavior_transition(behavior, Speed, transition_cost),
              by = Seg_id]

## 8-e. sous-segments homogÃ¨nes -------------------------------------------------
ais_data_core[, sub_seg_id := paste0(Seg_id, "_", rleid(behavior_smooth))]

# ==============================================================================
# 11. Score composite Dragage - VERSION AMÃ‰LIORÃ‰E SANS FUITE DE DONNÃ‰ES
# ==============================================================================

# ===== CRÃ‰ATION DES VARIABLES VITESSE PHYSIQUEMENT COHÃ‰RENTES =====

# 1. ProbabilitÃ© GMM pour la composante "dragage" (composante 3 typiquement)
# Cette variable capture l'information vitesse sans recopier l'Ã©tiquette
if (ncol(posterior_probs) >= 3) {
  ais_data_core[, prob_dredge_gmm := posterior_probs[, 3]]  # Composante 3 = dragage
} else {
  # Si moins de 3 composantes, utiliser celle avec vitesse moyenne ~2-3 kn
  gmm_means <- mclust_model$parameters$mean
  dredge_comp <- which.min(abs(gmm_means - 2.5))  # Composante la plus proche de 2.5 kn
  ais_data_core[, prob_dredge_gmm := posterior_probs[, dredge_comp]]
}

# 2. Vitesse normalisÃ©e continue (gaussienne centrÃ©e sur 2.25 kn)
mu_speed    <- 2.25          # centre de la plage dragage
sigma_speed <- 1.0           # largeur (~1 kn)
ais_data_core[, speed_norm := exp(-(Speed - mu_speed)^2 / (2 * sigma_speed^2))]

# 3. Indicateur vitesse dans fenÃªtre dragage (pour comparaison)
ais_data_core[, speed_in_dredge_range := as.integer(Speed >= 1.0 & Speed <= 3.5)]

# 4. Variables normalisÃ©es existantes (gardÃ©es)
q95_accel <- quantile(ais_data_core$Accel, 0.95, na.rm = TRUE)
ais_data_core[, norm_accel := pmax(0, pmin(1, Accel/q95_accel))]

# ===== SCORES COMPOSITES MULTIPLES POUR COMPARAISON =====

# Score 1: ANCIEN (avec fuite de donnÃ©es) - gardÃ© pour comparaison
ais_data_core[, dredging_indicator := as.integer(behavior_smooth=="dredging")]
ais_data_core[, dragage_score_OLD := 0.5*dredging_indicator +
                                     0.25*norm_course_change +
                                     0.25*norm_accel]

# Score 2: NOUVEAU - ProbabilitÃ© GMM + changements comportementaux
ais_data_core[, dragage_score_GMM := 0.5*prob_dredge_gmm +
                                     0.3*norm_course_change +
                                     0.2*norm_accel]

# Score 3: NOUVEAU - Vitesse normalisÃ©e + changements comportementaux  
ais_data_core[, dragage_score_SPEED := 0.5*speed_norm +
                                       0.3*norm_course_change +
                                       0.2*norm_accel]

# Score 4: NOUVEAU - Range vitesse + changements comportementaux
ais_data_core[, dragage_score_RANGE := 0.5*speed_in_dredge_range +
                                       0.3*norm_course_change +
                                       0.2*norm_accel]

# Ã‰tiquettes binaires
ais_data_core[, Dragage_OLD := as.integer(dragage_score_OLD >= 0.5)]
ais_data_core[, Dragage_GMM := as.integer(dragage_score_GMM >= 0.5)]
ais_data_core[, Dragage_SPEED := as.integer(dragage_score_SPEED >= 0.5)]
ais_data_core[, Dragage_RANGE := as.integer(dragage_score_RANGE >= 0.5)]

# Sauvegardes intermÃ©diaires avec les nouveaux scores
fwrite(ais_data_core, file.path(out_dir, "AIS_data_core_preprocessed.csv"))
saveRDS(ais_data_core, file.path(out_dir, "AIS_data_core_preprocessed.rds"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DBG-2 : Ã©tat mÃ©moire et diagnostic vitesse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
dbg_head("Ã‰tat avant grid-search - NOUVEAU SYSTÃˆME")
cat("MÃ©moire R utilisÃ©e :", dbg_mem_mb(), "Mo\n")
cat("nrow(ais_data_core) :", nrow(ais_data_core), "\n")

# Diagnostic des nouvelles variables vitesse
cat("\n=== DIAGNOSTIC VARIABLES VITESSE ===\n")
cat("ProbabilitÃ© GMM dragage - range:", 
    round(range(ais_data_core$prob_dredge_gmm, na.rm=TRUE), 3), "\n")
cat("Vitesse normalisÃ©e - range:", 
    round(range(ais_data_core$speed_norm, na.rm=TRUE), 3), "\n")
cat("% points dans range dragage [1-3.5 kn]:", 
    round(100*mean(ais_data_core$speed_in_dredge_range, na.rm=TRUE), 1), "%\n")

# CorrÃ©lations entre nouvelles variables et ancienne (pour validation)
cor_gmm_old <- cor(ais_data_core$prob_dredge_gmm, ais_data_core$dredging_indicator, use="complete.obs")
cor_speed_old <- cor(ais_data_core$speed_norm, ais_data_core$dredging_indicator, use="complete.obs")
cat("CorrÃ©lation prob_GMM vs dredging_indicator:", round(cor_gmm_old, 3), "\n")
cat("CorrÃ©lation speed_norm vs dredging_indicator:", round(cor_speed_old, 3), "\n")

# ===== CONTRÃ”LES ANTI-FUITE SUBTILE (recommandÃ©s par expert) =====
cat("\n=== CONTRÃ”LES MÃ‰THODOLOGIQUES AVANCÃ‰S ===\n")

## 3.1 CorrÃ©lations brutes score/label pour dÃ©tecter biais
truth_label <- as.integer(ais_data_core$behavior_smooth == "dredging")
for(s in c("dragage_score_GMM","dragage_score_SPEED","dragage_score_RANGE")){
  cor_val <- cor(ais_data_core[[s]], truth_label, use="complete.obs")
  cat(sprintf("%-20s â†’ cor = %.3f\n", s, cor_val))
}

## 3.2 AUC direct (sans Random Forest) pour baseline
library(pROC)
cat("\n--- AUC directs (sans modÃ¨le) ---\n")
roc_GMM   <- roc(truth_label, ais_data_core$dragage_score_GMM, quiet=TRUE)
roc_SPEED <- roc(truth_label, ais_data_core$dragage_score_SPEED, quiet=TRUE)
roc_RANGE <- roc(truth_label, ais_data_core$dragage_score_RANGE, quiet=TRUE)
cat("AUC GMM direct   :", round(auc(roc_GMM), 4), "\n")
cat("AUC SPEED direct :", round(auc(roc_SPEED), 4), "\n")
cat("AUC RANGE direct :", round(auc(roc_RANGE), 4), "\n")

## 3.3 Distribution des vitesses par classe (sanity check)
cat("\n--- Vitesses moyennes par comportement ---\n")
speed_by_behavior <- ais_data_core[, .(
  mean_speed = mean(Speed, na.rm=TRUE),
  median_speed = median(Speed, na.rm=TRUE),
  count = .N
), by = behavior_smooth]
print(speed_by_behavior)

## 3.4 Test de fuite temporelle : performance par annÃ©e
cat("\n--- Performance par annÃ©e (dÃ©tection fuite temporelle) ---\n")
for(yr in sort(unique(ais_data_core$Annee))) {
  yr_data <- ais_data_core[Annee == yr]
  if(nrow(yr_data) > 100) {  # Minimum de donnÃ©es
    yr_truth <- as.integer(yr_data$behavior_smooth == "dredging")
    if(length(unique(yr_truth)) == 2) {  # Les deux classes prÃ©sentes
      auc_yr <- auc(roc(yr_truth, yr_data$dragage_score_SPEED, quiet=TRUE))
      cat(sprintf("AnnÃ©e %d : AUC = %.3f (n=%d)\n", yr, auc_yr, nrow(yr_data)))
    }
  }
}

cat("\nâš ï¸  INTERPRÃ‰TATION CONTRÃ”LES :\n")
cat("â€¢ CorrÃ©lations > 0.8 â†’ possible sur-ajustement\n")
cat("â€¢ AUC directs > 0.9 â†’ fuite potentielle\n") 
cat("â€¢ AUC trÃ¨s variables par annÃ©e â†’ instabilitÃ© temporelle\n")
cat("â€¢ Si dragage â‰  vitesses 1-3.5kn â†’ problÃ¨me classification GMM\n")
flush.console()

# ======================================================================
# 12. Grid-search AMÃ‰LIORÃ‰ - 4 APPROCHES SANS FUITE DE DONNÃ‰ES
# ======================================================================
library(ranger)
library(pROC)

# ===== CONFIGURATION GRID-SEARCH =====
# Grille de poids pour w1 (vitesse), w2 (course), w3 (accel)
grid_w_temp <- expand.grid(
  w1 = seq(0.20, 0.80, 0.10),  # Vitesse : poids minimum 20% pour garder dominance
  w2 = seq(0.10, 0.60, 0.10),  # Course change
  w3 = seq(0.10, 0.60, 0.10)   # Acceleration
)
# Garder seulement les combinaisons qui somment Ã  ~1
grid_w <- grid_w_temp[abs(rowSums(grid_w_temp) - 1) < 0.05, ]

# âš ï¸ NOUVEAU : on force la somme exactement Ã  1
grid_w <- grid_w / rowSums(grid_w)

cat("â†’", nrow(grid_w), "combinaisons de poids Ã  tester\n")
cat("â†’ Poids vitesse (w1) entre", min(grid_w$w1), "et", max(grid_w$w1), "\n")

# ======================================================================
# 4.  FONCTIONS D'Ã‰VALUATION â€” VERSION CORRIGÃ‰E
# ======================================================================

# ---- 4.a  Validation croisÃ©e temporelle robuste ----------------------
eval_cross_validation_robust <- function(ais_tmp, approach_name, w) {
  ais_tmp[, label_tmp_num := as.integer(as.character(label_tmp))]

  if (length(unique(ais_tmp$label_tmp_num)) < 2) return(0.5)  # jeu trivial

  yrs  <- sort(unique(ais_tmp$Annee))
  aucs <- numeric(length(yrs))

  for (k in seq_along(yrs)) {
    yr    <- yrs[k]
    train <- copy(ais_tmp[Annee != yr])     # â¬…ï¸ copies indispensables
    test  <- copy(ais_tmp[Annee == yr])

    if (length(unique(train$label_tmp_num)) < 2 ||
        length(unique(test $label_tmp_num)) < 2) {
      aucs[k] <- 0.5
      next
    }

    # ---------- Recompute GMM dans le fold (Ã©vite fuite subtile) ---------
    if (approach_name == "GMM") {
      gmm_fold    <- Mclust(train$Speed, G = 1:5, verbose = FALSE)
      gmm_means   <- gmm_fold$parameters$mean
      dredge_comp <- which.min(abs(gmm_means - 2.5))

      train_z <- predict(gmm_fold, newdata = train$Speed)$z
      test_z  <- predict(gmm_fold, newdata =  test$Speed)$z

      train[, prob_gmm_fold := train_z[, dredge_comp]]
      test [, prob_gmm_fold :=  test_z [, dredge_comp]]

      train[, score_fold := w[1]*prob_gmm_fold   +
                            w[2]*norm_course_change +
                            w[3]*norm_accel]
      test [, score_fold := w[1]*prob_gmm_fold   +
                            w[2]*norm_course_change +
                            w[3]*norm_accel]
    } else {
      # SPEED, RANGE ou OLD : score dÃ©jÃ  pondÃ©rÃ©
      train[, score_fold := score_tmp]
      test [, score_fold := score_tmp]
    }

    # ---------- ModÃ¨le logistique ---------------------------------------
    glm_fit <- glm(label_tmp_num ~ score_fold,
                   data   = train,
                   family = binomial(link = "logit"))

    probs   <- predict(glm_fit, newdata = test, type = "response")
    aucs[k] <- pROC::auc(pROC::roc(test$label_tmp_num, probs, quiet = TRUE))
  }

  mean(aucs, na.rm = TRUE)
}

# ---- 4.b  Wrappers par approche (passent *w* au validateur) -----------

## GMM â€” ProbabilitÃ© de la composante dragage
eval_weights_GMM <- function(w) {
  ais_tmp <- ais_data_core[, .(
    score_tmp = w[1]*prob_dredge_gmm + w[2]*norm_course_change + w[3]*norm_accel,
    label_tmp = as.integer(behavior_smooth == "dredging"),
    Speed, norm_course_change, norm_accel, Annee
  )][complete.cases(score_tmp, label_tmp, Annee)]

  eval_cross_validation_robust(ais_tmp, "GMM", w)
}

## SPEED â€” Vitesse normalisÃ©e continue
eval_weights_SPEED <- function(w) {
  ais_tmp <- ais_data_core[, .(
    score_tmp = w[1]*speed_norm + w[2]*norm_course_change + w[3]*norm_accel,
    label_tmp = as.integer(behavior_smooth == "dredging"),
    Annee
  )][complete.cases(score_tmp, label_tmp, Annee)]

  eval_cross_validation_robust(ais_tmp, "SPEED", w)
}

## RANGE â€” Indicateur binaire (1 â‰¤ v â‰¤ 3.5 kn)
eval_weights_RANGE <- function(w) {
  ais_tmp <- ais_data_core[, .(
    score_tmp = w[1]*speed_in_dredge_range + w[2]*norm_course_change + w[3]*norm_accel,
    label_tmp = as.integer(behavior_smooth == "dredging"),
    Annee
  )][complete.cases(score_tmp, label_tmp, Annee)]

  eval_cross_validation_robust(ais_tmp, "RANGE", w)
}

## OLD â€” Variante avec fuite (contrÃ´le)
eval_weights_OLD <- function(w) {
  ais_tmp <- ais_data_core[, .(
    score_tmp = w[1]*dredging_indicator + w[2]*norm_course_change + w[3]*norm_accel,
    label_tmp = as.integer(behavior_smooth == "dredging"),
    Annee
  )][complete.cases(score_tmp, label_tmp, Annee)]

  eval_cross_validation_robust(ais_tmp, "OLD", w)
}

# ===== EXÃ‰CUTION DES 4 GRID-SEARCHES =====
DBG_PRINT_EVERY <- 10

cat("\nğŸ”¬ AMÃ‰LIORATIONS MÃ‰THODOLOGIQUES IMPLÃ‰MENTÃ‰ES :\n")
cat("â€¢ GMM rÃ©-entraÃ®nÃ© dans chaque fold (Ã©limination fuite subtile)\n")
cat("â€¢ GLM remplace Random Forest (plus stable, moins de variance)\n")
cat("â€¢ ContrÃ´les diagnostiques avancÃ©s effectuÃ©s\n")
cat("â€¢ Poids vitesse forcÃ©s â‰¥ 20% (dominance physique)\n")
cat("â†’ AUC attendus : SPEED/RANGE ~0.60-0.75, GMM ~0.70-0.85, OLD ~0.95+ (fuite)\n\n")

approaches <- list(
  "GMM" = list(name = "ProbabilitÃ© GMM robuste", func = eval_weights_GMM),
  "SPEED" = list(name = "Vitesse normalisÃ©e", func = eval_weights_SPEED), 
  "RANGE" = list(name = "Range vitesse binaire", func = eval_weights_RANGE),
  "OLD" = list(name = "ANCIEN (avec fuite dÃ©tectÃ©e)", func = eval_weights_OLD)
)

results_all <- list()

for (approach_name in names(approaches)) {
  approach <- approaches[[approach_name]]
  cat(sprintf("\n=== GRID SEARCH: %s ===\n", approach$name))
  
  auc_results <- numeric(nrow(grid_w))
  
  for (i in seq_len(nrow(grid_w))) {
    auc_results[i] <- approach$func(as.numeric(grid_w[i, ]))

    if (i %% DBG_PRINT_EVERY == 0 || i == nrow(grid_w)) {
      cat(sprintf("%s | %s | combo %2d/%2d | w1=%.1f w2=%.1f w3=%.1f | AUC=%.4f\n",
                  dbg_time(), approach_name, i, nrow(grid_w), 
                  grid_w[i,1], grid_w[i,2], grid_w[i,3], auc_results[i]))
      flush.console()
    }
  }
  
  # Sauvegarder rÃ©sultats
  best_idx <- which.max(auc_results)
  results_all[[approach_name]] <- list(
    best_weights = as.numeric(grid_w[best_idx, ]),
    best_auc = auc_results[best_idx],
    all_aucs = auc_results
  )
  
  cat(sprintf("âœ… %s - Meilleurs poids: w1=%.2f w2=%.2f w3=%.2f (AUC=%.4f)\n\n",
              approach$name, 
              results_all[[approach_name]]$best_weights[1],
              results_all[[approach_name]]$best_weights[2], 
              results_all[[approach_name]]$best_weights[3],
              results_all[[approach_name]]$best_auc))
}

# ===== COMPARAISON ET CHOIX FINAL =====
cat("=== COMPARAISON FINALE DES APPROCHES ===\n")
for (approach_name in names(approaches)) {
  res <- results_all[[approach_name]]
  cat(sprintf("%-25s: AUC=%.4f | w1=%.2f w2=%.2f w3=%.2f\n",
              approaches[[approach_name]]$name,
              res$best_auc, res$best_weights[1], res$best_weights[2], res$best_weights[3]))
}

# Identifier la meilleure approche (excluant OLD si AUC > 0.95)
best_approach <- NULL
best_auc_clean <- 0

for (approach_name in names(approaches)) {
  if (approach_name == "OLD") next  # Exclure l'ancienne mÃ©thode avec fuite
  
  auc <- results_all[[approach_name]]$best_auc
  if (auc > best_auc_clean) {
    best_auc_clean <- auc
    best_approach <- approach_name
  }
}

cat(sprintf("\nğŸ† MEILLEURE APPROCHE (sans fuite): %s (AUC=%.4f)\n", 
            approaches[[best_approach]]$name, best_auc_clean))

# VÃ©rification fuite de donnÃ©es
if (results_all[["OLD"]]$best_auc > 0.95) {
  cat("âš ï¸  CONFIRMATION: Approche OLD a AUC > 0.95 â†’ fuite de donnÃ©es dÃ©tectÃ©e\n")
} else {
  cat("â„¹ï¸  Approche OLD n'a pas d'AUC suspect (< 0.95)\n")
}

# ===== APPLICATION DU MEILLEUR SCORE =====
best_w <- results_all[[best_approach]]$best_weights
cat(sprintf("\nâ†’ Application des poids optimaux: w1=%.2f w2=%.2f w3=%.2f\n",
            best_w[1], best_w[2], best_w[3]))

if (best_approach == "GMM") {
  ais_data_core[, dragage_score_final := best_w[1]*prob_dredge_gmm + 
                                         best_w[2]*norm_course_change + 
                                         best_w[3]*norm_accel]
} else if (best_approach == "SPEED") {
  ais_data_core[, dragage_score_final := best_w[1]*speed_norm + 
                                         best_w[2]*norm_course_change + 
                                         best_w[3]*norm_accel]
} else if (best_approach == "RANGE") {
  ais_data_core[, dragage_score_final := best_w[1]*speed_in_dredge_range + 
                                         best_w[2]*norm_course_change + 
                                         best_w[3]*norm_accel]
}

ais_data_core[, Dragage_final := as.integer(dragage_score_final >= 0.5)]

# Sauvegardes finales avec rÃ©sultats complets
final_results <- list(
  best_approach = best_approach,
  best_weights = best_w,
  best_auc = best_auc_clean,
  all_approaches = results_all,
  method = "grid_search_sans_fuite_donnees"
)

saveRDS(final_results, file = file.path(out_dir, "grid_search_results_final.rds"))
saveRDS(ais_data_core, file = file.path(out_dir, "AIS_data_core_preprocessed.rds"))
fwrite(ais_data_core, file = file.path(out_dir, "AIS_data_core_preprocessed.csv"))

dbg_head("GRID-SEARCH AMÃ‰LIORÃ‰ TERMINÃ‰ AVEC SUCCÃˆS !")
cat("ğŸ¯ Vitesse redevient le critÃ¨re principal (w1 >=", min(grid_w$w1), ")\n")
cat("ğŸš« Fuite de donnÃ©es Ã©liminÃ©e\n") 
cat("ğŸ“Š RÃ©sultats sauvegardÃ©s dans :", out_dir, "\n") 